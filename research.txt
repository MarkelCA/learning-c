Glossary
------------------------------------------------------
Object file:
https://en.wikipedia.org/wiki/Object_file
Is a computer file containing object code, that is, machine code output of an assembler or compiler. The object code is usually relocatable, and not usually directly executable.

Chunks:
https://en.wikipedia.org/wiki/Fragmentation_(computing)
When a computer program requests blocks of memory from the computer system, the blocks are allocated in chunks. When the computer program is finished with a chunk, it can free it back to the system, making it available to later be allocated again to another or the same program. The size and the amount of time a chunk is held by a program varies. During its lifespan, a computer program can request and free many chunks of memory. When a program is started, the free memory areas are long and contiguous. Over time and with use, the long contiguous regions become fragmented into smaller and smaller contiguous areas. Eventually, it may become impossible for the program to obtain large contiguous chunks of memory.


Relocation(computing):
https://en.wikipedia.org/wiki/Relocation_(computing)
Relocation is the process of assigning load addresses for position-dependent code and data of a program and adjusting the code and data to reflect the assigned addresses. Prior to the advent of multiprocess systems the addresses for objects were absolute, starting at a known location (often zero). Since multiprocessing systems dynamically link animplified Wrapper and Interface Generator es una herramienta de software de código abierto utilizada para conectar programas de computadora o bibliotecas escritas en C o C ++ con lenguajes de scriptd switch between programs it became necessary to be able to relocate objects using position-independent code. A linker usually performs relocation in conjunction with symbol resolution 

Linker:
https://en.wikipedia.org/wiki/Linker_(computing)
In computing, a linker or link editor is a computer system program that takes one or more object files (generated by a compiler or an assembler) and combines them into a single executable file, library file, or another "object" file. A simpler version that writes its output directly to memory is called the loader, though loading is typically considered a separate process. Relocation is typically done by the linker at link time, but it can also be done at load time by a relocating loader, or at run time by the running program itself. Some architectures avoid relocation entirely by deferring address assignment to run time; this is known as zero address arithmetic.

Code segment:
https://en.wikipedia.org/wiki/Code_segment
Also known as a text segment or simply as text, is a portion of an object file or the corresponding section of the program's virtual address space that contains executable instructions (code).

Data segment:
https://en.wikipedia.org/wiki/Data_segment
In computing, a data segment (often denoted .data) is a portion of an object file or the corresponding address space of a program that contains initialized static variables, that is, global variables and static local variables. The size of this segment is determined by the size of the values in the program's source code, and does not change at run time. The data segment is read/write, since the values of variables can be altered at run time. This is in contrast to the read-only data segment (rodata segment or .rodata), which contains static constants rather than variables; it also contrasts to the code segment, also known as the text segment, which is read-only on many architectures.

Static variable:
https://en.wikipedia.org/wiki/Static_variable
In computer programming, a static variable is a variable that has been allocated "statically", meaning that its lifetime (or "extent") is the entire run of the program. This is in contrast to shorter-lived automatic variables, whose storage is stack allocated and deallocated on the call stack; and in contrast to objects, whose storage is dynamically allocated and deallocated in heap memory.

Non-volatile memory:
https://en.wikipedia.org/wiki/Non-volatile_memory
Non-volatile memory (NVM) or non-volatile storage is a type of computer memory that can retain stored information even after power is removed. In contrast, volatile memory needs constant power in order to retain data. Examples of non-volatile memory include flash memory, read-only memory (ROM), ferroelectric RAM, most types of magnetic computer storage devices (e.g. hard disk drives, floppy disks, and magnetic tape), optical discs, and early computer storage methods such as paper tape and punched cards.

Volatile memory:
https://en.wikipedia.org/wiki/Volatile_memory
Volatility can protect sensitive information, as it becomes unavailable on power-down. Most of the general-purpose random-access memory (RAM) is volatile.

DRAM:
https://en.wikipedia.org/wiki/Volatile_memory
Dynamic RAM (DRAM) is very popular due to its cost-effectiveness. DRAM stores each bit of information in a different capacitor within the integrated circuit. DRAM chips need just one single capacitor and one transistor to store each bit of information. This makes it space-efficient and inexpensive.[

SRAM:
https://en.wikipedia.org/wiki/Volatile_memory
The main advantage of static RAM (SRAM) is that it is much faster than dynamic RAM. Its disadvantage is its high price. SRAM does not need continuous electrical refreshes, but it still requires constant current to sustain the difference in voltage. Every single bit in a static RAM chip needs a cell of six transistors, whereas dynamic RAM requires only one capacitor and one transistor. As a result, SRAM is unable to accomplish the storage capabilities of the DRAM family. SRAM is commonly used as CPU cache and for processor registers and in networking devices.

Virtual memory:
https://en.wikipedia.org/wiki/Virtual_memory
The computer's operating system, using a combination of hardware and software, maps memory addresses used by a program, called virtual addresses, into physical addresses in computer memory. Address translation hardware in the CPU, often referred to as a memory management unit (MMU), automatically translates virtual addresses to physical addresses. The primary benefits of virtual memory include freeing applications from having to manage a shared memory space, ability to share memory used by libraries between processes, increased security due to memory isolation, and being able to conceptually use more memory than might be physically available, using the technique of paging or segmentation.

Virtual address space:
https://en.wikipedia.org/wiki/Virtual_address_space
In computing, a virtual address space (VAS) or address space is the set of ranges of virtual addresses that an operating system makes available to a process.

Adress space in application programming:
https://en.wikipedia.org/wiki/Memory_address#Address_space_in_application_programming
In modern multitasking environment, an application process usually has in its address space (or spaces) chunks of memory of following types:

Machine code:
    - program's own code (code segment / text segment)
    - shared libraries
Data:
    - initialized data (data segment)
    - uninitialized (but allocated) variables
    - run-time stack
    - heap
    - shared memory and memory mapped files


Procces isolation:
https://en.wikipedia.org/wiki/Process_isolation
Process isolation is a set of different hardware and software technologies designed to protect each process from other processes on the operating system. It does so by preventing process A from writing to process B. Process isolation can be implemented with virtual address space, where process A's address space is different from process B's address space – preventing A from writing onto B.

Thread(computing):
https://en.wikipedia.org/wiki/Thread_(computing)
Is the smallest sequence of programmed instructions that can be managed independently by a scheduler, which is typically a part of the operating system. The implementation of threads and processes differs between operating systems, but in most cases a thread is a component of a process. Multiple threads can exist within one process, executing concurrently and sharing resources such as memory, while different processes do not share these resources. In particular, the threads of a process share its executable code and the values of its dynamically allocated variables and non-thread-local global variables at any given time.

Data Structures
-----------------------------
Doubly vs Single linked lists: Singly linked list are generally used for implementation of stacks. On other hand doubly linked list can be used to implement stacks as well as heaps and binary trees.


Algorithms:
-----------------------------
Asymptotic Analysis:
Defining the mathematical boundation/framing of its run-time performance. Using asymptotic analysis, we can very well conclude the best case, average case, and worst case scenario of an algorithm.
